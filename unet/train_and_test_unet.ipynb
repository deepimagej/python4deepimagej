{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"unet_simple_github.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RSSaG4-n1qcO"},"source":["# **Mounts your drive**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BAEopvk_l7wg","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NL0Ji_OcLD-z","colab_type":"text"},"source":["Prepare data\n","==="]},{"cell_type":"code","metadata":{"id":"rhK06MkxLDTP","colab_type":"code","colab":{}},"source":["!pip install tifffile"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcdpETWxLDo7","colab_type":"code","colab":{}},"source":["# Functions\n","import numpy\n","import sys\n","sys.path.append(\"/content/drive/My Drive/.../unet_segmentation/py_files\") # path to py_files folder\n","from helpers import *\n","from data_loading import *\n","\n","# Autoreload\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Set random seed\n","np.random.seed(1)\n","\n","# Load raw data from the Cell Tracking Challenge http://celltrackingchallenge.net/2d-datasets/. Download first the data.\n","data, labels = load_data(\"/content/drive/My Drive/.../unet_segmentation/data/raw/hela/image/*.tif\",\n","                         \"/content/drive/My Drive/.../unet_segmentation/data/raw/hela/label/*.tif\") # Set correct paths\n","for i in range(len(labels)):\n","  tmp = np.array(labels[i])\n","  tmp[tmp > 0] = 255\n","  tmp[tmp == 0] = 0\n","  tmp = tmp.astype('uint8')\n","  tmp = Image.fromarray(tmp, 'L')\n","  labels[i] = tmp\n","  \n","# Split the data into train and test\n","X_train, y_train, X_test, y_test = split_data(data, labels, ratio = 0.5)\n","\n","# Set the paths and create the folders to save preprocessed data as .png\n","TRAIN_DIR=\"/content/drive/My Drive/unser_project/data/processed/hela/train/\"\n","TEST_DIR=\"/content/drive/My Drive/unser_project/data/processed/hela/test/\"\n","\n","if not os.path.exists(TRAIN_DIR):\n","    os.makedirs(TRAIN_DIR+\"/image/\")\n","    os.makedirs(TRAIN_DIR+\"/label/\")\n","    \n","if not os.path.exists(TEST_DIR):\n","    os.makedirs(TEST_DIR+\"/image/\")\n","    os.makedirs(TEST_DIR+\"/label/\")\n","    \n","# Save train and test files\n","save_data(X_train, y_train, TRAIN_DIR)\n","save_data(X_test, y_test, TEST_DIR)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1_qBzyHg1ohr"},"source":["# **Imports modules**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sk4cEzphpv4_","colab":{}},"source":["import sys\n","sys.path.append(\"/content/drive/My Drive/.../unet_segmentation/py_files\") # path to py_files folder\n","!pip install tifffile\n","!pip install --upgrade tensorflow\n","!pip install --upgrade keras\n","from model import *\n","from convert_to_pb import *\n","from data_loading import *\n","from helpers import *\n","from unet_weights import *\n","from fit_model import *\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import matplotlib\n","from PIL import Image, ImageOps, ImageFilter\n","import pickle\n","from test import *\n","import cv2 as cv\n","\n","# Autoreload\n","%load_ext autoreload\n","%autoreload 2\n","%reload_ext autoreload\n","\n","# Set random seed\n","np.random.seed(1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ifxpZTDtmyPn","colab_type":"text"},"source":["Train U-Net\n","==="]},{"cell_type":"markdown","metadata":{"id":"fqOD0FTkJMCT","colab_type":"text"},"source":["## Hela cells"]},{"cell_type":"code","metadata":{"id":"Kb0aNeIKy6cj","colab_type":"code","colab":{}},"source":["# Load training and validation data\n","# Note that the subset of generator used for the training generator is \"validation\" because we don't want to augment our data\n","# Specify paths where inside there are \"image\" and \"label\" folder\n","trainGen = dataGenerator(batch_size = 2, subset = \"train\", path = '/content/drive/My Drive/.../unet_segmentation/data/processed/hela/train')\n","validGen = dataGenerator(batch_size = 1, subset = \"validation\", path = '/content/drive/My Drive/.../unet_segmentation/data/processed/hela/test')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6A5LXMcPQUV9","colab_type":"code","colab":{}},"source":["model = unet()\n","\n","# Callbacks\n","model_checkpoint = ModelCheckpoint('/content/drive/My Drive/.../unet_segmentation/models/{b}.hdf5'.format(b=\"unet_hela\"), monitor='val_loss', verbose=1, save_best_only=True)\n","\n","# Fit\n","history = model.fit_generator(trainGen,\n","                          steps_per_epoch=500,\n","                          epochs=1,\n","                          callbacks=[model_checkpoint], \n","                          validation_data = validGen, \n","                              validation_steps = 9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bWigI7T0Mlyp","colab_type":"text"},"source":["Results\n","==="]},{"cell_type":"markdown","metadata":{"id":"59BUzz8bc_GN","colab_type":"text"},"source":["## Hela cells"]},{"cell_type":"code","metadata":{"id":"xf_rj9545A2j","colab_type":"code","colab":{}},"source":["# Define paths.\n","    path_to_model = '/content/drive/My Drive/.../unet_segmentation/models/unet_hela.hdf5'\n","   \n","    # Load model.\n","    model = load_model(path_to_model)\n","    # Load training and validation data\n","    # Note that the subset of generator used for the training generator is \"validation\" because we don't want to augment our data\n","    print(\"Validation\")\n","    validGen = dataGenerator(batch_size = 1, subset = \"validation\", path = '/content/drive/My Drive/.../unet_segmentation/data/processed/hela/test')\n","    \n","    accuracies = model.evaluate_generator(validGen, steps=9, verbose=1) \n","    print(accuracies)\n","    \n","    print(\"Training\")\n","    trainGen = dataGenerator(batch_size = 1, subset = \"validation\", path = '/content/drive/My Drive/.../unet_segmentation/data/processed/hela/train')\n","    \n","    accuracies = model.evaluate_generator(validGen, steps=8, verbose=1) \n","    print(accuracies)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UoRhKGShIvke","colab_type":"text"},"source":["Prediction\n","==="]},{"cell_type":"code","metadata":{"id":"7zq_yID3jP8G","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vccfXzFJIu6z","colab_type":"code","colab":{}},"source":["from tensorflow.contrib.saved_model import save_keras_model\n","import tensorflow.keras\n","from keras.models import load_model\n","testGen = dataGenerator(batch_size = 1, subset = \"test\", path = '/content/drive/My Drive/.../unet_segmentation/data/processed/hela/test')\n","model = unet()\n","model = load_model('/content/drive/My Drive/.../unet_segmentation/models/unet_hela.hdf5')\n","results = model.predict_generator(testGen,9,verbose=1, workers=1)\n","#saveResults('/content/drive/My Drive/.../unet_segmentation/data/hela/test/', results, convert = True)\n","#saveResults('/content/drive/My Drive/.../unet_segmentation/data/hela/test/', results, convert = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wIRWpNL0XC_Q","colab_type":"code","colab":{}},"source":["from sklearn.metrics import jaccard_similarity_score\n","  \n","acc_tot = [];\n","\n","for i in range(9):\n","  label = cv.imread('/content/drive/My Drive/.../unet_segmentation/data/hela/test/label/0{b}.png'.format(b=i))\n","  label = cv.resize(label, (256,256))\n","  acc = jaccard_similarity_score(label[...,0].flatten(), convertLabel(results[i]).flatten())\n","  acc_tot.append(acc)\n","     \n","print(\"Jaccard average : {b}\".format(b=np.mean(acc_tot)))"],"execution_count":0,"outputs":[]}]}